{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#필요한 라이브러리를 불러봅시다.\n",
    "#sys, os는 부모 디렉토리까지 파일을 가져올 수 있도록 해줍니다.\n",
    "#numpy는 행렬 계산을 편리하게 해줍니다.\n",
    "#PIL은 Mnist데이터들을 간단하게 그려줍니다.\n",
    "#dataset.mnist는 mnist데이터를 불러옵니다.\n",
    "#matplotlib은 그래프를 편리하게 그릴 수 있게 해줍니다.\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from mnist import load_mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#이미지 확인 및 저장을 위한 간단한 코드입니다.\n",
    "def img_show(img) : \n",
    "\timg = Image.fromarray(np.uint8(img))\n",
    "\timg.show()\n",
    "def img_save(img, name) :\n",
    "\timg = Image.fromarray(np.uint8(img))\n",
    "\timg.save(name + \".png\", \"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#이번 실습에서는 계단함수로 Relu를 사용할 것입니다.\n",
    "#0 이하의 값들은 모두 0으로 처리하여 전파합니다.\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#각 Layer를 표현하는 부분입니다. Weight 행렬 W, bias의 b, 그리고 input x로 이루어져 있습니다.\n",
    "#dw, db는 역전파 때 기울기를 저장하기 위함입니다.\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W =W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "        return out\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dataset을 가져옵니다.  인터넷에 연결되어 있어야 하며, 몇 분까지 걸릴 수 있습니다.\n",
    "#x는 28*28픽셀로 표현된 0~9까지의 흑백 숫자 이미지입니다.\n",
    "#t는 10차원 벡터로써, 현재 이미지가 몇을 나타내는지를 나타냅니다.\n",
    "#예를 들어, [0,1,0,0,0,0,0,0,0] 라면 이 이미지는 1임을 나타냅니다.0-9 순서입니다.\n",
    "\n",
    "#normalize : 0-255까지의 숫자로 밝기를 표시하지만, 이를 정규화시켜 0-1로 변환합니다.\n",
    "#flatten : 28*28의 형태인 이미지를 일렬로 펴 784*1로 만들어 줍니다.\n",
    "#one_hot_label : 특정 객체의 정보를 목록으로 만든 후, 0과 1로 나타내는 것을 뜻합니다.\n",
    "#t의 형태가 대표적인 one_hot_label의 예시입니다.\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, flatten =True, one_hot_label = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#다양한 세팅값들입니다.\n",
    "#iters_num : 학습을 몇 번 반복할 지 표시합니다.\n",
    "#train_size : training set의 크기입니다.\n",
    "#batch_size : batch의 크기입니다. batch란 한 번에 학습시킬 양 정도로 생각하시면 되겠습니다.\n",
    "#learning rate : 학습속도입니다. 너무 빠르면 엉뚱한 곳을 겉돌며 영원히 답을 찾을 수 없을 수도 있습니다.\n",
    "#반대로 너무 작으면 답을 찾는데 너무 오래 걸릴 것입니다. cost function 부문을 검색해보세요.\n",
    "#batch_mask : 전체 training set중에 어느 것을 batch로 사용할 지 결정합니다.\n",
    "#weight_init_std : Weight들을 초기화할 때 쓸 변수입니다.\n",
    "#input layer는 28픽셀(784), hidden layer는 50, output layer는 다시 784로 설정합니다.\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.00003\n",
    "batch_mask = batch_mask = np.random.choice(train_size, batch_size)\n",
    "weight_init_std = 0.01\n",
    "input_size = x_train[0].shape[0]\n",
    "hidden_size = 50\n",
    "output_size = input_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#각 레이어의 Weight들과 bias를 초기화 해봅시다.\n",
    "#W는 0-1 사이의 값을 무작위로 선정한 후, weight_init_std를 곱해줍니다.\n",
    "#b는 0으로 설정합니다.\n",
    "\n",
    "params={}\n",
    "params['W1'] = weight_init_std * np.random.randn(input_size , hidden_size)\n",
    "params['b1'] = np.zeros(hidden_size)\n",
    "params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "params['b2'] = np.zeros(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#위의 값들을 가지고 layer를 만들어봅시다.\n",
    "#hidden layer는 Relu를 포함합니다.\n",
    "layers = {}\n",
    "layers['Affine1'] = Affine(params['W1'], params['b1'])\n",
    "layers['Relu'] = Relu()\n",
    "layers['Affine2'] = Affine(params['W2'], params['b2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "9.06142662356\n",
      "1000\n",
      "9.60793543987\n",
      "2000\n",
      "9.07231848014\n",
      "3000\n",
      "8.63376693756\n",
      "4000\n",
      "9.29801333683\n",
      "5000\n",
      "9.7553046386\n",
      "6000\n",
      "10.3642240275\n",
      "7000\n",
      "9.24153216889\n",
      "8000\n",
      "9.09657230767\n",
      "9000\n",
      "9.27201365493\n"
     ]
    }
   ],
   "source": [
    "#이제 학습을 시켜봅시다. batch사이즈만큼의 인풋을 설정하고, 이를 하나씩 전파시킵니다.\n",
    "#전파가 완료되면, 역전파를 하며 기울기를 구합니다.\n",
    "#이후 각 기울기만큼 w와 b를 업데이트합니다.\n",
    "#매 1000번째 학습시마다 현재의 loss를 Mean squared Error로 출력해봅니다.\n",
    "#loss는 결과적으로 점점 줄어듭니다.\n",
    "\n",
    "for i in range(iters_num) : \n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = np.copy(x_train[batch_mask])\n",
    "    t_batch = np.copy(x_train[batch_mask])\n",
    "    grads = {}\n",
    "    #forward\n",
    "    a1 = x_batch\n",
    "    z1 = layers['Affine1'].forward(a1)\n",
    "    a2 = layers['Relu'].forward(z1)\n",
    "    z2 = layers['Affine2'].forward(a2)\n",
    "    #get loss by the output - original input\n",
    "    loss = z2 - t_batch\n",
    "    #backpropagation\n",
    "    dout = loss\n",
    "    dout=layers['Affine2'].backward(dout)\n",
    "    dout=layers['Relu'].backward(dout)\n",
    "    dout=layers['Affine1'].backward(dout)\n",
    "    #update gradients\n",
    "    grads['W1'] = layers['Affine1'].dW\n",
    "    grads['b1'] = layers['Affine1'].db\n",
    "    grads['W2'] = layers['Affine2'].dW\n",
    "    grads['b2'] = layers['Affine2'].db\n",
    "    #update parameters\n",
    "    for key in ('W1', 'b1', 'W2', 'b2') :\n",
    "        params[key] -= learning_rate * grads[key]\n",
    "    #check the losses\n",
    "    if (i % 1000 == 0):\n",
    "        print(i)\n",
    "        print(np.sum(loss**2) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#이제 완성된autoencoder를 실행해봅시다.\n",
    "#training set의 1~10번째 사진을 input으로 넣어보고, output과 원본을 비교해봅시다.\n",
    "#저장하지 않고 즉석해서 보고 싶다면, img_show()를 이용하면 됩니다.\n",
    "for k in range(11):\n",
    "    a1 = x_train[k]\n",
    "    z1 = layers['Affine1'].forward(a1)\n",
    "    a2 = layers['Relu'].forward(z1)\n",
    "    z2 = layers['Affine2'].forward(a2)\t\n",
    "    z2 = z2.reshape(28,28)\n",
    "    z2 = z2*256\n",
    "    a1 = (a1*256).reshape(28,28)\n",
    "    img_save(a1, \"input\" + str(k))\n",
    "    img_save(z2, \"output\" + str(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
